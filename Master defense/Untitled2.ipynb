{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load modules (install floris)\n",
    "from floris.floris import Floris\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy\n",
    "import gpflow\n",
    "import GPy\n",
    "import random\n",
    "import time\n",
    "\n",
    "from pygmo import hypervolume\n",
    "\n",
    "# Visualization\n",
    "from copy import deepcopy\n",
    "from visualization_manager import VisualizationManager\n",
    "from pareto import Pareto\n",
    "from scipy.optimize import minimize\n",
    "from scipy.stats import norm\n",
    "from pareto import Pareto\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def windFarmPower(floris,wd, ws, yawAngle,scale):\n",
    "    \n",
    "    #set up wind direction and speed\n",
    "    floris.farm.flow_field.wind_direction = np.radians(wd - 270) # frame of reference is west\n",
    "    floris.farm.flow_field.wind_speed = ws\n",
    "    floris.farm.flow_field.initial_flowfield = floris.farm.flow_field._initial_flowfield()\n",
    "    floris.farm.flow_field.u_field = floris.farm.flow_field._initial_flowfield()\n",
    "    \n",
    "    \n",
    "    turbines    = [turbine for _, turbine in floris.farm.flow_field.turbine_map.items()]\n",
    "    for k,turbine in enumerate(turbines):\n",
    "        turbine.yaw_angle = np.radians(yawAngle[k])\n",
    "    floris.farm.flow_field.calculate_wake()\n",
    "    \n",
    "    power = np.zeros([len(yawAngle),1])\n",
    "    totalPower = 0.0\n",
    "    for i, turbine in enumerate(turbines):\n",
    "        power[i]=turbine.power\n",
    "        totalPower = totalPower + turbine.power    \n",
    "    \n",
    "    return power/scale, totalPower/scale/len(turbines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 0.0):\n",
      "\tCp - 0.46328782548262326\n",
      "\tCt - 0.7661304442831962\n",
      "\tpower - 1712005.1679717556\n",
      "\tai - 0.2581996920407235\n",
      "\taverage velocity - 7.85065163365446\n"
     ]
    }
   ],
   "source": [
    "#run wind farm configuration input with a single wind turbine\n",
    "floris = Floris(\"example_input_single.json\")\n",
    "numWT = 1\n",
    "scale = 1.0\n",
    "#conventional default input is yawAngle = 0 degree\n",
    "yawAngle0 = np.zeros(numWT)\n",
    "\n",
    "#compute the wind turbine power vector and total wind farm power (for single wind turbine they are the same)\n",
    "powerSingle,totalPower = windFarmPower(floris,0, 8, yawAngle0,scale)\n",
    "\n",
    "for coord, turbine in floris.farm.turbine_map.items():\n",
    "    print(str(coord) + \":\")\n",
    "    print(\"\\tCp -\", turbine.Cp)\n",
    "    print(\"\\tCt -\", turbine.Ct)\n",
    "    print(\"\\tpower -\", turbine.power)\n",
    "    print(\"\\tai -\", turbine.aI)\n",
    "    print(\"\\taverage velocity -\", turbine.get_average_velocity())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "floris = Floris(\"example_input_double.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99999909]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wd=180;\n",
    "ws=8;\n",
    "num_tur = len(floris.farm.flow_field.turbine_map.items())\n",
    "yawAngle = np.ones(num_tur)*0.01\n",
    "power, totalPower = windFarmPower(floris, wd, 8, yawAngle, powerSingle)\n",
    "totalPower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hypervolume_poi(Xcand, gp_models, pareto, reference, outdim, wind_dir):\n",
    "    Xcand = np.atleast_2d(Xcand)\n",
    "    Xcand = np.hstack((Xcand, np.ones((len(Xcand), 1)) * wind_dir))\n",
    "    num_cells = pareto.bounds.lb.shape[0]\n",
    "    N = Xcand.shape[0]\n",
    "\n",
    "    # Extended Pareto front\n",
    "    pf_ext = np.concatenate([-np.inf * np.ones([1, outdim], dtype=float), pareto.front, reference], 0)\n",
    "\n",
    "    # Predictions for candidates, concatenate columns\n",
    "    preds = [m.predict(Xcand) for m in gp_models]\n",
    "    candidate_mean, candidate_var = (np.concatenate(moment, 1) for moment in zip(*preds))\n",
    "    candidate_var = np.maximum(candidate_var, 1e-6)  # avoid zeros\n",
    "\n",
    "    # Calculate the cdf's for all candidates for every predictive distribution in the data points\n",
    "    normal = scipy.stats.norm(candidate_mean, np.sqrt(candidate_var))\n",
    "    Phi = np.transpose(normal.cdf(np.expand_dims(pf_ext, 1)), [1, 0, 2])  # N x pf_ext_size x outdim\n",
    "    # tf.gather_nd indices for bound points\n",
    "    col_idx = np.tile(range(outdim), (num_cells,))\n",
    "    ub_idx = np.stack((np.reshape(pareto.bounds.ub, [-1]), col_idx), axis=1).astype(int)  # (num_cells*outdim x 2)\n",
    "    lb_idx = np.stack((np.reshape(pareto.bounds.lb, [-1]), col_idx), axis=1).astype(int)  # (num_cells*outdim x 2)\n",
    "    \n",
    "    # Calculate PoI\n",
    "    P1 = np.zeros((N, num_cells*outdim))\n",
    "    P2 = np.zeros((N, num_cells*outdim))\n",
    "    for i in range(len(ub_idx)):\n",
    "        for k in range(N):\n",
    "            P1[k,i] = np.transpose(Phi, [1, 2, 0])[ub_idx[i][0],ub_idx[i][1], k]  # N x num_cell*outdim\n",
    "            P2[k,i] = np.transpose(Phi, [1, 2, 0])[lb_idx[i][0],lb_idx[i][1], k]  # N x num_cell*outdim\n",
    "    P = np.reshape(P1 - P2, [N, num_cells, outdim])\n",
    "    PoI = np.sum(np.prod(P, axis=2), axis=1, keepdims=True)  # N x 1\n",
    "\n",
    "    # Calculate Hypervolume contribution of points Y\n",
    "    ub_points = np.zeros((1, num_cells*outdim))\n",
    "    lb_points = np.zeros((1, num_cells*outdim))\n",
    "    for i in range(len(ub_idx)):\n",
    "        ub_points[0,i] = pf_ext[ub_idx[i][0],ub_idx[i][1]]\n",
    "        lb_points[0,i] = pf_ext[lb_idx[i][0],lb_idx[i][1]]\n",
    "    ub_points = np.reshape(ub_points, [num_cells, outdim])\n",
    "    lb_points = np.reshape(lb_points, [num_cells, outdim])\n",
    "\n",
    "    splus_valid = np.all(np.tile(np.expand_dims(ub_points, 1), [1, N, 1]) > candidate_mean,\n",
    "                                axis=2)  # num_cells x N\n",
    "    splus_idx = np.expand_dims(splus_valid.astype(np.float64), -1)  # num_cells x N x 1\n",
    "    splus_lb = np.tile(np.expand_dims(lb_points, 1), [1, N, 1])  # num_cells x N x outdim\n",
    "    splus_lb = np.maximum(splus_lb, candidate_mean)  # num_cells x N x outdim\n",
    "    splus_ub = np.tile(np.expand_dims(ub_points, 1), [1, N, 1])  # num_cells x N x outdim\n",
    "    splus = np.concatenate([splus_idx, splus_ub - splus_lb], axis=2)  # num_cells x N x (outdim+1)\n",
    "    Hv = np.transpose(np.sum(np.prod(splus, axis=2), axis=0, keepdims=True))  # N x 1\n",
    "    \n",
    "    # return HvPoI\n",
    "    return -np.multiply(Hv, PoI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_next_point(acquisition, gp_model, bounds, pareto, reference, outdim, wind_dir, N_mc = 5000):\n",
    "    \"\"\"\n",
    "    acquisition : acquisition function of Gaussian processes\n",
    "    gp_model : gpflow Gaussian process model\n",
    "    eval_y : evaluated y list in current state\n",
    "    bounds : boundary of next point\n",
    "    n_restarts : number of restarts for scipy.minimize\n",
    "    \n",
    "    return : next x    \n",
    "    \"\"\"\n",
    "    best_x = None\n",
    "    best_acquisition_value = 0\n",
    "    n_params = bounds.shape[0]\n",
    "    points = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(N_mc, n_params))\n",
    "    evaluations = acquisition(points, gp_model, pareto, reference, outdim, wind_dir)\n",
    "    idx_best = np.argmin(evaluations, axis=0)\n",
    "    \n",
    "    result = minimize(fun=acquisition, x0=points[idx_best, :], bounds=bounds, method='L-BFGS-B',args=(gp_model, pareto, reference, outdim, wind_dir))\n",
    "    if result.fun <= best_acquisition_value:\n",
    "        best_acquisition_value = result.fun\n",
    "        best_x = result.x\n",
    "\n",
    "    return best_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multiobj_f(yawangle):\n",
    "    Y1 = np.zeros(len(yawangle))[:,None]\n",
    "    Y2 = np.zeros(len(yawangle))[:,None]\n",
    "    for i,angle in enumerate(yawangle):\n",
    "        power,totalPower = windFarmPower(floris, angle[-1], 8, angle[:-1], powerSingle)\n",
    "        Y1[i] = -totalPower\n",
    "        Y2[i] = np.sum(np.square(np.radians(angle[:-1]))) / np.square(np.radians(25.0)) / num_tur\n",
    "    Y = np.hstack((Y1,Y2))\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum_yaw_angle = 0.0\n",
    "maximum_yaw_angle = 25.0\n",
    "\n",
    "bounds = np.zeros((num_tur, 2))\n",
    "for i in range(num_tur):\n",
    "    bounds[i,:] = [minimum_yaw_angle, maximum_yaw_angle]\n",
    "    \n",
    "# number of turbines + wind context\n",
    "n_params = bounds.shape[0]+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial data point of wind-farm\n",
    "init_sample = 1\n",
    "wd_init = np.random.uniform(90, 120, size=(init_sample, 1))\n",
    "\n",
    "X = np.zeros((init_sample, bounds.shape[0]))\n",
    "for i, yawangles in enumerate(np.random.uniform(bounds[:, 0], bounds[:, 1], (init_sample, bounds.shape[0]))):\n",
    "    X[i,:] = yawangles\n",
    "X = np.hstack((X, wd_init))\n",
    "Y = multiobj_f(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/cwj/venv/local/lib/python3.5/site-packages/GPy/kern/src/stationary.py:166: RuntimeWarning:overflow encountered in true_divide\n",
      " /home/cwj/venv/local/lib/python3.5/site-packages/GPy/kern/src/stationary.py:138: RuntimeWarning:invalid value encountered in add\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "1.6493444442749023\n"
     ]
    }
   ],
   "source": [
    "num_output = Y.shape[1]\n",
    "num_iter = 8\n",
    "wd_context = np.random.uniform(90, 120, size=(num_iter, 1))\n",
    "t1 = time.time()\n",
    "    \n",
    "for i in range(num_iter):\n",
    "    print(i)\n",
    "    pareto = Pareto(np.empty((0, num_output)))\n",
    "    reference = np.ones((1, num_output))\n",
    "\n",
    "    if i == 0:\n",
    "        gp_models = [GPy.models.GPRegression(X.copy(), Y[:,[i]].copy(), kernel= GPy.kern.Matern52(input_dim=n_params, ARD=True)) for i in range(Y.shape[1])]\n",
    "    elif i%5 != 0:\n",
    "        gp_models = [GPy.models.GPRegression(X.copy(), Y[:,[i]].copy(), kernel= gp_models[i].kern, noise_var = gp_models[i].likelihood[0] ) for i in range(Y.shape[1])]\n",
    "    else:\n",
    "        gp_models = [GPy.models.GPRegression(X.copy(), Y[:,[i]].copy(), kernel= gp_models[i].kern, noise_var = gp_models[i].likelihood[0] ) for i in range(Y.shape[1])]\n",
    "        for m in gp_models:\n",
    "            m.optimize()\n",
    "    \n",
    "    trusted_X = np.array([X[j] for j in range(len(X)) if wd_context[i]-30 <= X[j,-1] <= wd_context[i]+30])\n",
    "    context_X = np.hstack((trusted_X[:,:-1], np.ones((len(trusted_X), 1)) * wd_context[i]))    \n",
    "    preds =  [m.predict(context_X) for m in gp_models]\n",
    "    context_Y, var = (np.concatenate(moment, 1) for moment in zip(*preds))\n",
    "    pareto.update(context_Y)\n",
    "    pf = pareto.front\n",
    "    f = np.max(pf, axis=0, keepdims=True) - np.min(pf, axis=0, keepdims=True)\n",
    "    reference = np.max(pf, axis=0, keepdims=True) + 2 * f / pf.shape[0]\n",
    "       \n",
    "    next_point = np.atleast_2d(sample_next_point(hypervolume_poi, gp_models, bounds, pareto, reference, num_output, wd_context[i]))\n",
    "    next_point = np.hstack((next_point, np.ones((1,1)) * wd_context[i]))\n",
    "    X = np.append(X, next_point, axis = 0)\n",
    "    function_value = multiobj_f(np.atleast_2d(next_point))\n",
    "    Y = np.append(Y, function_value, axis = 0)\n",
    "t2 = time.time()\n",
    "print(t2-t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "extended = np.tile(pareto.Y, (pareto.Y.shape[0], 1, 1))\n",
    "dominance = np.sum(np.logical_and(np.all(extended <= np.swapaxes(extended, 0, 1), axis=2),\n",
    "                                  np.any(extended < np.swapaxes(extended, 0, 1), axis=2)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[-7.73379789e-01,  4.24653149e-01],\n",
       "        [-7.73809290e-01,  4.44670241e-01],\n",
       "        [-6.89312303e-01, -2.09266489e-07],\n",
       "        [-7.40432153e-01,  2.26048466e-01]]), array([2, 0, 4, 0, 2, 3, 0, 0]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pareto.Y[dominance == 0], dominance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 3],\n",
       "       [1, 2],\n",
       "       [2, 1],\n",
       "       [3, 0]])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argsort(pareto.front, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0],\n",
       "       [1, 4],\n",
       "       [2, 3],\n",
       "       [3, 2],\n",
       "       [4, 1],\n",
       "       [5, 5]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outdim = 2\n",
    "pf_idx = np.argsort(pareto.front, axis=0)\n",
    "pf_ext_idx = np.vstack((np.zeros(outdim, dtype=np.int32), pf_idx + 1,\n",
    "                        np.ones(outdim, dtype=np.int32) * pareto.front.shape[0] + 1))\n",
    "pf_ext_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 5\n",
      "\n",
      "1 0\n",
      "2 1\n",
      "\n",
      "2 0\n",
      "3 2\n",
      "\n",
      "3 0\n",
      "4 3\n",
      "\n",
      "4 0\n",
      "5 4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(pf_ext_idx[-1, 0]):\n",
    "    print(i, 0)\n",
    "    print(i+1, pf_ext_idx[-i-1, 1])\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.64706381,  0.66700547]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(pareto.front, axis=0, keepdims=True) + 2 * f / pareto.front.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = pareto.front\n",
    "reference = np.max(pf, axis=0, keepdims=True) + 2 * f / pf.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xcand = next_point\n",
    "num_cells = pareto.bounds.lb.shape[0]\n",
    "N = Xcand.shape[0]\n",
    "\n",
    "# Extended Pareto front\n",
    "pf_ext = np.concatenate([-np.inf * np.ones([1, outdim], dtype=float), pareto.front, reference], 0)\n",
    "\n",
    "# Predictions for candidates, concatenate columns\n",
    "preds = [m.predict(Xcand) for m in gp_models]\n",
    "candidate_mean, candidate_var = (np.concatenate(moment, 1) for moment in zip(*preds))\n",
    "candidate_var = np.maximum(candidate_var, 1e-6)  # avoid zeros\n",
    "\n",
    "# Calculate the cdf's for all candidates for every predictive distribution in the data points\n",
    "normal = scipy.stats.norm(candidate_mean, np.sqrt(candidate_var))\n",
    "Phi = np.transpose(normal.cdf(np.expand_dims(pf_ext, 1)), [1, 0, 2])  # N x pf_ext_size x outdim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  -inf,   -inf],\n",
       "       [-0.774,  0.445],\n",
       "       [-0.773,  0.425],\n",
       "       [-0.74 ,  0.226],\n",
       "       [-0.689, -0.   ],\n",
       "       [-0.647,  0.667]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.round(pf_ext,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.75636357,  0.29728938]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.00000000e+000, 0.00000000e+000]],\n",
       "\n",
       "       [[3.53040542e-002, 1.00000000e+000]],\n",
       "\n",
       "       [[4.75501116e-002, 1.00000000e+000]],\n",
       "\n",
       "       [[1.00000000e+000, 2.37340304e-013]],\n",
       "\n",
       "       [[1.00000000e+000, 9.89055387e-222]],\n",
       "\n",
       "       [[1.00000000e+000, 1.00000000e+000]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal.cdf(np.expand_dims(pf_ext, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi[0][2] = 0.04, 0.98\n",
    "Phi[0][3] = 0.98, 0.02\n",
    "Phi[0][4] = 0.99, 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0]\n",
      " [5 1]\n",
      " [2 0]\n",
      " [1 1]\n",
      " [3 0]\n",
      " [2 1]\n",
      " [4 0]\n",
      " [3 1]\n",
      " [5 0]\n",
      " [4 1]]\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [2 0]\n",
      " [0 1]\n",
      " [3 0]\n",
      " [0 1]\n",
      " [4 0]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "col_idx = np.tile(range(outdim), (num_cells,))\n",
    "ub_idx = np.stack((np.reshape(pareto.bounds.ub, [-1]), col_idx), axis=1).astype(int)  # (num_cells*outdim x 2)\n",
    "lb_idx = np.stack((np.reshape(pareto.bounds.lb, [-1]), col_idx), axis=1).astype(int)  # (num_cells*outdim x 2)\n",
    "print(ub_idx)\n",
    "print(lb_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate PoI\n",
    "P1 = np.zeros((N, num_cells*outdim))\n",
    "P2 = np.zeros((N, num_cells*outdim))\n",
    "for i in range(len(ub_idx)):\n",
    "    for k in range(N):\n",
    "        P1[k,i] = np.transpose(Phi, [1, 2, 0])[ub_idx[i][0],ub_idx[i][1], k]  # N x num_cell*outdim\n",
    "        P2[k,i] = np.transpose(Phi, [1, 2, 0])[lb_idx[i][0],lb_idx[i][1], k]  # N x num_cell*outdim\n",
    "P = np.reshape(P1 - P2, [N, num_cells, outdim])\n",
    "PoI = np.sum(np.prod(P, axis=2), axis=1, keepdims=True)  # N x 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  ],\n",
       "        [0.  ]],\n",
       "\n",
       "       [[0.03],\n",
       "        [0.99]],\n",
       "\n",
       "       [[0.04],\n",
       "        [0.98]],\n",
       "\n",
       "       [[0.98],\n",
       "        [0.02]],\n",
       "\n",
       "       [[0.99],\n",
       "        [0.01]],\n",
       "\n",
       "       [[1.  ],\n",
       "        [1.  ]]])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.transpose(Phi, [1, 2, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.03, 1.  ],\n",
       "        [0.04, 0.99],\n",
       "        [0.98, 0.98],\n",
       "        [0.99, 0.02],\n",
       "        [1.  , 0.01]]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(P1, [N,num_cells,outdim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.  , 0.  ],\n",
       "        [0.03, 0.  ],\n",
       "        [0.04, 0.  ],\n",
       "        [0.98, 0.  ],\n",
       "        [0.99, 0.  ]]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.reshape(P2, [N,num_cells,outdim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Hypervolume contribution of points Y\n",
    "ub_points = np.zeros((1, num_cells*outdim))\n",
    "lb_points = np.zeros((1, num_cells*outdim))\n",
    "for i in range(len(ub_idx)):\n",
    "    ub_points[0,i] = pf_ext[ub_idx[i][0],ub_idx[i][1]]\n",
    "    lb_points[0,i] = pf_ext[lb_idx[i][0],lb_idx[i][1]]\n",
    "ub_points = np.reshape(ub_points, [num_cells, outdim])\n",
    "lb_points = np.reshape(lb_points, [num_cells, outdim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "splus_valid = np.all(np.tile(np.expand_dims(ub_points, 1), [1, N, 1]) > candidate_mean,\n",
    "                            axis=2)  # num_cells x N\n",
    "splus_idx = np.expand_dims(splus_valid.astype(np.float64), -1)  # num_cells x N x 1\n",
    "splus_lb = np.tile(np.expand_dims(lb_points, 1), [1, N, 1])  # num_cells x N x outdim\n",
    "splus_lb = np.maximum(splus_lb, candidate_mean)  # num_cells x N x outdim\n",
    "splus_ub = np.tile(np.expand_dims(ub_points, 1), [1, N, 1])  # num_cells x N x outdim\n",
    "splus = np.concatenate([splus_idx, splus_ub - splus_lb], axis=2)  # num_cells x N x (outdim+1)\n",
    "Hv = np.transpose(np.sum(np.prod(splus, axis=2), axis=0, keepdims=True))  # N x 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[       -inf,        -inf]],\n",
       "\n",
       "       [[-0.77380929,        -inf]],\n",
       "\n",
       "       [[-0.77337979,        -inf]],\n",
       "\n",
       "       [[-0.74043215,        -inf]],\n",
       "\n",
       "       [[-0.6893123 ,        -inf]]])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.tile(np.expand_dims(lb_points, 1), [1, N, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.76821882,  0.29268916]],\n",
       "\n",
       "       [[-0.76821882,  0.29268916]],\n",
       "\n",
       "       [[-0.76821882,  0.29268916]],\n",
       "\n",
       "       [[-0.74043215,  0.29268916]],\n",
       "\n",
       "       [[-0.6893123 ,  0.29268916]]])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splus_lb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 0.        , -0.00559047,  0.37431631]],\n",
       "\n",
       "       [[ 0.        , -0.00516097,  0.15198108]],\n",
       "\n",
       "       [[ 1.        ,  0.02778666,  0.13196399]],\n",
       "\n",
       "       [[ 0.        ,  0.05111985, -0.0666407 ]],\n",
       "\n",
       "       [[ 0.        ,  0.04224849, -0.29268937]]])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.        ],\n",
       "       [-0.        ],\n",
       "       [ 0.00366684],\n",
       "       [-0.        ],\n",
       "       [-0.        ]])"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.prod(splus, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 4, 0, 2, 3, 0, 0])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.logical_and(np.all(extended <= np.swapaxes(extended, 0, 1), axis=2),\n",
    "                                  np.any(extended < np.swapaxes(extended, 0, 1), axis=2)), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[22.98427679, 18.32308058],\n",
       "       [18.5577584 , 17.79271085],\n",
       "       [ 1.92835755,  7.21801334],\n",
       "       [21.99461056,  8.46549208],\n",
       "       [18.35027392, 18.7385134 ],\n",
       "       [18.67232717, 12.16198247],\n",
       "       [ 4.98785331, 24.850071  ],\n",
       "       [ 0.57735326,  0.38854877],\n",
       "       [15.32600135,  6.14972245],\n",
       "       [12.79589151, 13.938944  ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params = bounds.shape[0]\n",
    "points = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(10, 2))\n",
    "points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/cwj/venv/local/lib/python3.5/site-packages/ipykernel_launcher.py:17: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    }
   ],
   "source": [
    "num_output = 2\n",
    "pareto = Pareto(np.empty((0, num_output)))\n",
    "ref = np.array([[3,3]]) \n",
    "y = np.array([[0,2], [2,0], [1,1]])\n",
    "pareto.update(y)\n",
    "pf = pareto.front\n",
    "ext1, ext2 = np.array([[-np.inf, ref[0][1]]]), np.array([[ref[0][0], -np.inf]])\n",
    "pf_ext = np.concatenate([ext1, pareto.front, ext2], 0)\n",
    "\n",
    "predicted_mean, predicted_var = np.array([[0,0]]), np.array([[0.01,0.01]])\n",
    "normal1 = scipy.stats.norm(predicted_mean[:,0], np.sqrt(predicted_var[:,0]))\n",
    "normal2 = scipy.stats.norm(predicted_mean[:,1], np.sqrt(predicted_var[:,1]))\n",
    "\n",
    "P1 = np.zeros((1, len(pf)+1))\n",
    "P2 = np.zeros((1, len(pf)+1))\n",
    "for i in range(len(pf)+1):\n",
    "    P1[0,i] = (pf_ext[i+1, 0] - pf_ext[i, 0]) * normal1.cdf(pf_ext[i, 0]) * exipsi(pf_ext[i, 1], pf_ext[i, 1], normal2) \n",
    "    P2[0,i] = (exipsi(pf_ext[i+1, 0], pf_ext[i+1, 0], normal1) - exipsi(pf_ext[i+1, 0], pf_ext[i, 0], normal1)) * exipsi(pf_ext[i, 1], pf_ext[i, 1], normal2)\n",
    "    if i == 0:\n",
    "        P1[i] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.7978845608028653"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(P1 + P2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EHVI(Xcand, gp_models, pareto, reference, wind_dir, outdim = 2):\n",
    "    Xcand = np.atleast_2d(Xcand)\n",
    "    Xcand = np.hstack((Xcand, np.ones((len(Xcand), 1)) * wind_dir))\n",
    "\n",
    "    ext1, ext2 = np.array([[-np.inf, reference[0][1]]]), np.array([[reference[0][0], -np.inf]])\n",
    "    pf_ext = np.concatenate([ext1, pareto.front, ext2], 0)\n",
    "\n",
    "    # Predictions for candidates, concatenate columns\n",
    "    preds = [m.predict(Xcand) for m in gp_models]\n",
    "    candidate_mean, candidate_var = (np.concatenate(moment, 1) for moment in zip(*preds))\n",
    "    candidate_var = np.maximum(candidate_var, 1e-6)  # avoid zeros\n",
    "    \n",
    "    normal1 = scipy.stats.norm(candidate_mean[:,0], np.sqrt(candidate_var[:,0]))\n",
    "    normal2 = scipy.stats.norm(candidate_mean[:,1], np.sqrt(candidate_var[:,1]))\n",
    "    \n",
    "    P1 = np.zeros((points.shape[0], len(pareto.front)+1))\n",
    "    P2 = np.zeros((points.shape[0], len(pareto.front)+1))\n",
    "\n",
    "    for i in range(len(pf)+1):\n",
    "        P1[:,i] = (pf_ext[i+1, 0] - pf_ext[i, 0]) * normal1.cdf(pf_ext[i, 0]) * exipsi(pf_ext[i, 1], pf_ext[i, 1], normal2) \n",
    "        P2[:,i] = (exipsi(pf_ext[i+1, 0], pf_ext[i+1, 0], normal1) - exipsi(pf_ext[i+1, 0], pf_ext[i, 0], normal1)) * exipsi(pf_ext[i, 1], pf_ext[i, 1], normal2)\n",
    "        if i == 0:\n",
    "            P1[:,i] = 0\n",
    "            \n",
    "    return -np.sum(P1 + P2, axis = 1)[:,None]\n",
    "\n",
    "def exipsi(a, b, normal):\n",
    "    return normal.std() * normal.pdf(b) + (a-normal.mean()) * normal.cdf(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " /home/cwj/venv/local/lib/python3.5/site-packages/ipykernel_launcher.py:20: RuntimeWarning:invalid value encountered in multiply\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-4.13449953e-02],\n",
       "       [-2.70182969e-02],\n",
       "       [-7.18810937e-18],\n",
       "       [-1.45068752e-20],\n",
       "       [-3.33597523e-04],\n",
       "       [-1.68288111e-12],\n",
       "       [-2.91586712e-07],\n",
       "       [-7.25272427e-27],\n",
       "       [-1.74504667e-03],\n",
       "       [-3.58715442e-17]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params = bounds.shape[0]\n",
    "points = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(10, n_params))\n",
    "\n",
    "EHVI(points, gp_models, pareto, reference, wd_context[i], outdim = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.000297]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hypervolume_poi(next_point, gp_models, pareto, reference, 2, wd_context[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.ones([1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.33333333, 3.33333333]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = np.max(pareto.front, axis=0, keepdims=True) - np.min(pareto.front, axis=0, keepdims=True)\n",
    "np.max(pareto.front, axis=0, keepdims=True) + 2 * f / pareto.front.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
